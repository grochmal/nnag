{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demystifying Neural Networks \n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {
    "scratch.svg": {
     "image/svg+xml": [
      "<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   id="svg14023"
   version="1.1"
   viewBox="0 0 270.93333 67.733335"
   height="256"
   width="1024"
   sodipodi:docname="scratch.svg"
   inkscape:version="0.92.4 5da689c313, 2019-01-14">
  <sodipodi:namedview
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1"
     objecttolerance="10"
     gridtolerance="10"
     guidetolerance="10"
     inkscape:pageopacity="0"
     inkscape:pageshadow="2"
     inkscape:window-width="1920"
     inkscape:window-height="1061"
     id="namedview6225"
     showgrid="false"
     inkscape:zoom="1.6738281"
     inkscape:cx="512"
     inkscape:cy="128"
     inkscape:window-x="0"
     inkscape:window-y="19"
     inkscape:window-maximized="0"
     inkscape:current-layer="svg14023" />
  <defs
     id="defs14017" />
  <metadata
     id="metadata14020">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title></dc:title>
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <g
     transform="matrix(-0.125,0,0,0.125,260.58678,45.425007)"
     id="layer1">
    <g
       transform="translate(-28.66907,-106.87106)"
       id="g16913">
      <path
         style="fill:#ff2a2a;fill-opacity:1;stroke:#ff0000;stroke-width:0.26458332px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
         d="m 61.868962,264.42618 153.145448,0.26729 -0.26727,-256.845994 151.44965,0.29188 -1.24418,-75.394621 c 0,0 -2.93997,-21.381561 -14.43254,-33.408685 -11.4926,-12.02713 -38.85207,-22.59963 -59.06658,-26.45969 -53.18663,-10.15626 -99.9588,-9.08718 -155.01633,0.53454 -12.63742,2.20848 -36.08139,9.35443 -51.048479,27.796031 -14.967094,18.441598 -21.648832,34.2105 -21.381562,43.832203 0.267269,9.621702 -2.138157,319.387046 -2.138157,319.387046 z"
         id="path14197" />
      <circle
         style="fill:#ffffff;fill-opacity:1;stroke:none;stroke-width:0.79374999;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1"
         id="path14199"
         cx="300.05096"
         cy="-59.518368"
         r="30.238094" />
      <path
         style="fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.26458332px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
         d="m 229.33705,26.652511 c 0,0 7.27604,-10.48885 16.72545,-9.732882 9.4494,0.755941 11.33928,2.456841 11.52827,9.449408 0.18899,6.992541 1.88988,17.953858 0.18899,22.489583 -1.70089,4.535699 -6.23661,7.370525 -10.96131,7.9375 -4.7247,0.566949 -11.1503,-2.645833 -13.41815,-3.96875 -2.26786,-1.322916 -3.02381,-3.779784 -3.02381,-3.779784 0,0 -3.02381,4.535725 -6.80358,4.724717 -3.77976,0.188992 -6.55006,0.546947 -8.82185,-0.65577 -2.27179,-1.202716 -4.00904,-1.870895 -4.00904,-1.870895 0,0 -3.34087,7.617195 -7.61718,10.557166 -4.27631,2.939944 -10.28988,5.211736 -17.10525,4.543584 -6.81537,-0.668179 -12.6953,-2.672715 -14.03165,-6.54812 -1.33635,-3.875405 -1.20271,-16.570695 -1.20271,-20.713382 0,-4.142687 -0.13364,-9.220809 0,-12.160753 0.13363,-2.939971 0.26727,-5.7463 2.93996,-7.884451 2.6727,-2.138177 7.08264,-3.74179 14.83346,-3.340894 7.75082,0.400923 13.36348,3.60815 16.03617,6.949017 2.6727,3.340867 3.87541,5.612659 3.87541,5.612659 0,0 3.96318,-3.354308 7.20956,-4.015767 3.27361,-0.667007 6.05696,-0.810103 8.77126,-0.182267 2.7143,0.627836 4.886,2.590081 4.886,2.590081 z"
         id="path16882" />
      <path
         style="fill:#000000;fill-opacity:1;stroke:none;stroke-width:3;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1"
         d="M 1128.9004,1000.7266 A 182.661,182.661 0 0 0 952.71094,1135.3535 L 337.14258,1135 234.28516,1178.5723 c 0,0 -14.286,15.7129 -2.85743,40.7129 11.42857,25 30,27.1425 30,27.1425 l 97.85743,-38.5703 588.38672,-2.7929 a 182.661,182.661 0 0 0 181.22852,160.9843 182.661,182.661 0 0 0 182.6621,-182.6621 182.661,182.661 0 0 0 -0.6328,-12.6426 55.381768,55.381768 0 0 0 18.4258,3.2168 55.381768,55.381768 0 0 0 55.3828,-55.3828 55.381768,55.381768 0 0 0 -5.8145,-24.6523 88.716802,88.716802 0 0 1 6.5567,-0.2656 88.716802,88.716802 0 0 1 88.7168,88.7168 88.716802,88.716802 0 0 1 -88.7168,88.7168 88.716802,88.716802 0 0 1 -4.6875,-0.2344 l 0.7832,47.5039 a 138.21428,138.21428 0 0 0 5.9238,0.209 138.21428,138.21428 0 0 0 138.2148,-138.2149 138.21428,138.21428 0 0 0 -138.2148,-138.2148 138.21428,138.21428 0 0 0 -62.4922,15.0976 c 1.8444,1.9397 3.6232,3.9497 5.3516,6.0078 a 55.381768,55.381768 0 0 0 -1.0039,-0.051 55.381768,55.381768 0 0 0 -45.4922,23.9082 182.661,182.661 0 0 0 -154.9629,-86.3789 z m 0,55.5586 a 127.1026,127.1026 0 0 1 127.1035,127.1015 127.1026,127.1026 0 0 1 -127.1035,127.1035 127.1026,127.1026 0 0 1 -127.1016,-127.1035 127.1026,127.1026 0 0 1 127.1016,-127.1015 z"
         transform="matrix(0.26458333,0,0,0.26458333,0,-380.33335)"
         id="path16888" />
    </g>
  </g>
  <g
     aria-label="Neural Nets
(from scratch)"
     style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:19.75555611px;line-height:1.25;font-family:'Rock Salt';-inkscape-font-specification:'Rock Salt';text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.26458332"
     id="text6229"
     transform="translate(-22.129911,-0.79035395)">
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 67.494099,11.476535 c -1.792993,3.225099 -0.284073,9.373656 -1.40836,13.909916 -0.176175,5.606109 -5.727902,3.934257 -7.524085,0.289391 -1.323985,-1.548884 -3.853122,-10.201804 -3.954985,-4.012847 -0.41163,3.837656 -1.494901,7.761468 -1.23471,11.556228 -2.17659,2.366557 -3.264422,-2.40249 -1.446936,-4.321529 -0.131327,-2.537371 0.85887,-5.585196 1.234731,-8.006402 1.438234,-2.977392 -1.671656,-7.970748 0.27011,-9.993528 3.221702,0.957844 2.310167,6.10883 4.18648,8.585173 1.118851,1.91156 3.958186,9.539904 6.463002,6.327944 0.795402,-3.706029 0.862699,-7.015227 0.983928,-10.861698 0.303483,-2.458483 -0.634239,-4.859333 -1.041792,-7.080358 2.063637,-0.7212915 2.577016,2.362637 3.472617,3.60771 z"
       id="path6233"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 81.326848,17.052078 c -2.638597,1.579657 -10.448887,-0.544458 -9.819903,4.36011 1.811894,0.553928 7.620708,-2.207608 6.308656,1.041806 -2.139991,1.467847 -7.647228,-0.231167 -6.983893,3.414779 -0.883392,4.350492 4.644941,3.546647 5.324737,0.359478 3.968255,-3.332897 -0.280181,6.358796 -3.626996,5.081013 -3.513331,0.30628 -4.378962,-4.190925 -3.665578,-6.887438 0.543007,-2.361083 -0.602572,-6.212028 2.141476,-6.964608 2.895384,-1.585646 8.005547,-2.057287 10.321501,-0.405146 z"
       id="path6235"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 92.420055,26.196739 c -3.357278,5.012 -4.068673,-5.884615 -6.173611,-0.212217 -2.861993,4.985962 -8.042084,1.030711 -5.903513,-3.49195 0.0023,-3.645076 4.859835,-7.076169 2.257227,-1.273305 -1.929721,2.627928 0.242039,6.717069 2.508034,3.3762 2.638674,-1.255044 1.461214,-7.120799 5.073934,-6.289369 0.964649,2.778986 -0.779844,6.628689 2.237929,7.890641 z"
       id="path6237"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 117.73186,25.965229 c -3.05329,1.965726 -7.80182,1.183908 -11.42118,2.315107 -6.19042,2.472924 -8.523809,-4.63807 -2.10289,-6.733088 6.26329,-4.923402 -3.6736,-4.168506 -6.713793,-2.257218 -0.05655,2.979386 -1.357401,7.097032 1.061086,9.414756 -2.145804,4.553356 -4.39523,-4.338351 -3.221853,-6.771678 0.968815,-3.630565 -1.24067,-0.971957 -2.662369,-1.948542 -0.740237,-2.154372 3.926561,-3.102907 5.594833,-3.472656 3.179976,-0.319187 12.008656,-3.053656 10.360086,2.720248 -0.10341,2.584282 -10.030194,7.319541 -3.70411,7.311864 4.19635,-0.275871 8.4601,-1.409027 12.57875,-0.81029 l 0.23151,0.23151 z"
       id="path6239"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 126.60643,27.913775 c -1.42252,1.540843 -4.63106,1.427818 -5.2091,-1.118964 -1.82081,-1.336753 -4.83152,0.63015 -7.25399,0.154325 -0.55355,1.905293 -5.12792,5.004743 -3.39551,1.254013 1.6166,-2.53613 3.97537,-5.515987 5.34403,-8.681643 0.45751,-4.452473 4.56241,-8.075654 5.09321,-1.215429 -0.0986,3.613233 2.68347,6.196144 3.53063,7.813481 -3.51666,0.716867 1.97511,0.813174 1.89073,1.794217 z m -6.03857,-3.086806 c -0.82806,-3.413256 -1.64951,-10.042573 -3.62699,-3.163978 -3.83852,4.661724 1.14016,3.451222 3.62699,3.163978 z"
       id="path6241"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 136.96652,24.363949 c -0.82377,1.977271 -3.68726,2.787299 -5.68649,3.646291 -2.54283,1.022738 -5.0599,-1.320589 -4.39693,-4.091748 1.85281,-2.553446 -1.82119,-7.493879 2.07685,-7.831043 2.49493,2.477903 -0.86459,6.554382 0.50149,9.704145 2.34537,1.180655 5.24136,-2.193769 7.50508,-1.427645 z"
       id="path6243"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 161.75743,11.476535 c -1.793,3.225086 -0.28407,9.373656 -1.40835,13.909916 -0.17622,5.606109 -5.72796,3.934255 -7.52416,0.289391 -1.324,-1.548899 -3.85305,-10.201785 -3.95502,-4.012847 -0.41174,3.837676 -1.49497,7.761543 -1.23491,11.556228 -2.17656,2.366541 -3.2646,-2.402378 -1.44702,-4.321526 -0.13131,-2.537324 0.8589,-5.585209 1.23481,-8.006402 1.43838,-2.977371 -1.67176,-7.970833 0.27011,-9.993528 3.29444,1.096826 2.34629,6.391007 4.37943,8.990316 0.96829,1.828884 4.09143,9.281087 6.27007,5.845631 0.81705,-3.674401 0.85168,-6.964027 0.98398,-10.784528 0.30343,-2.458454 -0.63422,-4.859338 -1.04184,-7.080358 2.06385,-0.7213839 2.57676,2.363 3.4729,3.607707 z"
       id="path6245"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 175.59018,17.052078 c -2.6386,1.579656 -10.44889,-0.544458 -9.81992,4.36011 1.8119,0.55392 7.6207,-2.2076 6.30869,1.041806 -2.14001,1.467856 -7.64728,-0.231175 -6.98401,3.414779 -0.88343,4.350508 4.645,3.546643 5.32478,0.359478 3.96825,-3.332896 -0.28019,6.358797 -3.627,5.081013 -3.51341,0.306261 -4.37898,-4.190929 -3.6656,-6.887438 0.54307,-2.36107 -0.60266,-6.212036 2.14148,-6.964608 2.89543,-1.58565 8.00547,-2.057281 10.32158,-0.405146 z"
       id="path6247"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 191.27501,16.91703 c -0.96264,3.399764 -4.70354,1.428903 -7.48564,2.700963 -4.90463,-1.474926 -3.03524,3.290467 -2.72033,6.077144 3.24986,-1.144854 0.5478,4.57804 -1.50483,2.700957 -2.80924,-1.644943 0.81861,-8.736963 -3.02901,-8.12215 -4.56989,1.405671 -2.83865,-3.238454 1.23471,-2.276515 4.25726,-0.39562 8.52032,-0.570203 12.27008,-2.04501 0.8569,-0.01026 0.32008,1.29632 1.23502,0.964611 z"
       id="path6249"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 198.77981,26.891271 c 0.15097,3.349847 -9.0055,5.866859 -7.46622,1.929256 5.55646,1.011641 6.60372,-4.023139 0.73311,-3.125381 -4.92404,-0.128003 -5.14747,-5.13504 -1.79418,-7.446911 1.35194,-0.954208 5.3353,-4.777594 5.47915,-1.25402 -1.38204,1.816727 -6.71904,2.74293 -5.26686,5.942098 2.52287,1.498483 7.74022,-0.277345 8.315,3.954958 z"
       id="path6251"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 36.982954,59.842921 c -3.837905,0.275249 -6.79833,-4.020026 -7.292575,-7.485504 -0.158428,-4.553982 1.095218,-9.799736 3.881337,-13.34917 2.012382,-1.613379 3.092191,1.511993 1.327657,2.48747 -2.77183,3.341868 -3.881398,8.877393 -2.353678,13.022461 0.379822,2.837901 3.20548,3.298559 4.437259,5.324743 z"
       id="path6253"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 53.555242,41.553598 c -2.328911,1.865347 -6.596568,0.132393 -9.45334,1.215424 -3.928338,-1.10343 -5.722859,9.073088 -1.254011,5.633421 1.868607,-0.472736 3.811942,-1.379415 5.691295,-1.890668 7.268916,-0.0062 -3.844485,2.439842 -5.36332,4.070718 -4.59295,0.238608 -0.318109,4.537353 -3.877794,4.745966 -3.397263,-2.485782 0.08643,-7.337522 -1.369774,-9.626973 -2.473092,-1.723676 3.121425,-4.100977 5.112517,-4.649503 3.250995,-0.224835 8.049425,-2.137459 10.514427,0.501615 z"
       id="path6255"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 77.092136,50.659674 c -3.053286,1.965722 -7.801824,1.183896 -11.421181,2.315098 -6.190421,2.472926 -8.523809,-4.638076 -2.102886,-6.733087 6.263286,-4.923403 -3.673599,-4.168508 -6.713797,-2.257219 -0.05655,2.979386 -1.3574,7.097032 1.061086,9.414757 -2.145803,4.553355 -4.395232,-4.338351 -3.221853,-6.771678 0.968816,-3.630567 -1.240672,-0.971955 -2.66237,-1.948541 -0.740237,-2.154372 3.926561,-3.102907 5.594833,-3.472656 3.179979,-0.319187 12.008644,-3.053657 10.360092,2.720258 -0.103404,2.584272 -10.030143,7.319495 -3.704173,7.311874 4.196344,-0.275869 8.460095,-1.409029 12.578735,-0.81029 l 0.23151,0.23151 z"
       id="path6257"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 83.82523,42.846197 c -0.330091,3.621279 -1.217471,8.206398 -5.266859,9.376168 -3.821101,3.489721 -10.485206,-1.125087 -6.77168,-5.710591 1.958636,-2.903771 4.81787,-5.491969 8.430829,-6.424417 1.868741,-0.08685 2.985142,1.125048 3.60771,2.75884 z m -1.929253,1.003212 c -1.906032,-1.755378 -3.998477,-0.887668 -5.942098,1.099683 -6.168155,3.803967 -0.03572,9.399636 3.993553,4.20577 1.345698,-1.438407 1.683721,-3.454492 1.948545,-5.305453 z"
       id="path6259"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 103.71584,51.585716 c -4.19167,5.457345 -5.668921,-4.190039 -4.032167,-7.253996 -1.724138,2.984639 -4.59097,6.273378 -8.392254,5.768458 -2.979908,-1.940265 -3.344448,-8.541262 -3.569109,-1.639866 -1.463013,2.107004 1.14417,4.58269 -0.231492,6.038567 -3.995407,0.776283 -1.783336,-5.717939 -1.832784,-7.929237 -0.579636,-3.450718 3.593555,-9.283855 4.649497,-3.337615 -0.518984,6.867636 7.184048,4.902088 8.006397,-0.624439 1.141329,-4.643765 4.961952,-0.955954 3.569142,2.68874 -0.19552,2.390423 -2.177002,6.744639 1.83277,6.289388 z"
       id="path6261"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 122.6611,51.585716 c 0.15099,3.349845 -9.0055,5.866859 -7.46621,1.929256 5.55647,1.011638 6.6037,-4.023145 0.7331,-3.125381 -4.92404,-0.127994 -5.14748,-5.135049 -1.79418,-7.446911 1.23183,-1.378958 6.6112,-4.820355 5.0933,-0.598073 -1.83349,0.752009 -7.13513,3.287324 -4.39871,5.633417 2.64638,0.714541 7.29875,-0.192662 7.8327,3.607692 z"
       id="path6263"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 138.26877,50.543919 c -1.92682,2.796569 -6.18835,1.890185 -9.22186,2.180043 -3.96302,-0.149423 -7.39166,-4.620536 -4.76527,-8.276497 2.72663,-2.494865 7.33424,-4.570524 10.86175,-2.430845 0.8071,4.260748 -3.09671,1.229303 -4.34082,1.118965 -2.87312,0.311979 -6.9781,3.3084 -4.51451,6.28937 3.11891,3.234656 7.99558,1.779469 11.98071,1.118964 z"
       id="path6265"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 162.78958,50.659674 c -3.05329,1.965721 -7.80182,1.183895 -11.42118,2.315098 -6.19042,2.472924 -8.52382,-4.638072 -2.10289,-6.733087 6.26328,-4.923408 -3.67359,-4.168503 -6.71382,-2.257219 -0.0565,2.979294 -1.35757,7.097222 1.06119,9.414757 -2.14583,4.553354 -4.39522,-4.338375 -3.22186,-6.771678 0.96888,-3.630586 -1.24073,-0.971943 -2.66243,-1.948541 -0.74026,-2.154379 3.92655,-3.102905 5.59482,-3.472656 3.17998,-0.319185 12.00864,-3.053659 10.36009,2.720258 -0.10341,2.584289 -10.0302,7.319522 -3.70412,7.311874 4.19635,-0.27587 8.46011,-1.409027 12.57876,-0.81029 l 0.23151,0.23151 z"
       id="path6267"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 171.66415,52.60822 c -1.42252,1.540844 -4.63106,1.427817 -5.2091,-1.118964 -1.82081,-1.336761 -4.83152,0.630168 -7.25399,0.154336 -0.55355,1.905293 -5.12792,5.004743 -3.39551,1.254013 1.48465,-2.22772 3.56437,-5.050198 4.93176,-7.768941 1.17807,-2.215228 2.50396,-9.35761 4.88812,-4.539707 0.90479,3.460696 1.48409,8.749202 4.22513,9.70414 -2.74283,2.144893 0.7547,0.692944 1.81359,2.315123 z m -6.03857,-3.086805 c -0.82806,-3.413256 -1.64951,-10.042575 -3.62699,-3.163979 -3.83852,4.661702 1.14017,3.451255 3.62699,3.163979 z"
       id="path6269"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 187.13676,41.611475 c -0.96264,3.399764 -4.70354,1.428903 -7.48564,2.700963 -4.90461,-1.474931 -3.03525,3.290484 -2.72033,6.077144 3.24986,-1.144854 0.5478,4.57804 -1.50483,2.700957 -2.80923,-1.644947 0.81862,-8.736964 -3.029,-8.12215 -4.56989,1.405693 -2.83864,-3.238444 1.23471,-2.276515 4.25727,-0.395619 8.52031,-0.570205 12.27009,-2.045011 0.85689,-0.01025 0.32007,1.296311 1.235,0.964612 z"
       id="path6271"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 198.9052,50.543919 c -1.92684,2.79657 -6.18835,1.890184 -9.22187,2.180043 -3.96302,-0.149422 -7.39166,-4.620537 -4.76527,-8.276497 2.72663,-2.494867 7.33424,-4.570524 10.86175,-2.430845 0.80708,4.260755 -3.0967,1.229297 -4.34082,1.118965 -2.87313,0.311975 -6.9781,3.308406 -4.51451,6.28937 3.11892,3.234652 7.99558,1.779472 11.98072,1.118964 z"
       id="path6273"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 210.7894,45.006961 c -2.35072,1.512565 -1.31369,4.860521 -0.88754,7.331162 -0.0156,3.995621 -2.91878,1.239247 -2.46954,-1.717021 1.17934,-4.671752 -3.12942,-5.892453 -5.4598,-2.122179 -0.39057,2.497398 2.9172,6.716149 -1.23472,4.495161 -1.27276,-2.664455 -0.0535,-6.284207 -3.80064,-3.935676 -1.89244,-2.791456 6.07256,-2.377098 3.65112,-6.790974 -0.96649,-4.887241 3.15205,-2.206418 1.86659,1.292597 -0.0625,3.81915 7.27586,0.35012 4.47583,-3.549826 1.97047,-3.894887 1.81489,4.078729 3.45336,4.475871 l 0.40514,0.520898 z"
       id="path6275"
       inkscape:connector-curvature="0" />
    <path
       style="font-size:19.75555611px;text-align:center;text-anchor:middle;stroke-width:0.26458332"
       d="m 218.60289,50.293116 c -0.0665,4.078143 -2.27178,7.733734 -4.89064,10.495136 -3.41764,-0.423933 1.31003,-3.880414 1.43735,-5.864931 2.41563,-4.316718 1.13434,-9.304293 -1.00332,-13.427601 -3.18545,-3.485741 1.67167,-2.429299 2.52735,0.771704 1.02445,2.568647 2.01687,5.208357 1.92926,8.025692 z"
       id="path6277"
       inkscape:connector-curvature="0" />
  </g>
</svg>
"
     ]
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scratch.svg](attachment:scratch.svg)\n",
    "\n",
    "<div style=\"text-align:right;font-size:0.7em;\">scratch.svg</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a lot of mathematics but not too much code.\n",
    "Are ANN libraries actually big, in term of lines of code?\n",
    "To be fair, yes, several libraries have dozens of JVPs and lost of optimizations.\n",
    "Yet, a full minimal implementation of an ANN library does not need to be big.\n",
    "\n",
    "We will try a minimal working (buggy) product that can train an ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3278, 8) (3278,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./pulsars_tuned.csv')\n",
    "X, y = df.values[:, :-1], df['label'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just need to transform the data as previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3278, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = np.c_[y == 0, y == 1].astype(np.float)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And import what we will need.\n",
    "\n",
    "In order to avoid implementing our own list inspection\n",
    "(`autograd` inspects a list if it is differentiating that argument)\n",
    "we will use the `inspect` package and differentiate against all arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from functools import wraps\n",
    "import operator as op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like `autograd` and `pytorch` we will build our own wrapper on `numpy`.\n",
    "This can be a very thin wrapper, we only need two things from it:\n",
    "\n",
    "1. As we perform operations using our `numpy` wrapper a graph is built.\n",
    "2. The array must be aware of the fact that it is an array node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Node (follows)\n",
    "\n",
    "def drop_wrapper(*args):\n",
    "    return [a.val if isinstance(a, Node) else a for a in args]\n",
    "\n",
    "node_functions = [\n",
    "    np.mean,\n",
    "    np.log,\n",
    "    np.tanh,\n",
    "]\n",
    "\n",
    "\n",
    "class NumpyWrap(object):\n",
    "\n",
    "    def __getattr__(self, key):\n",
    "        fn = getattr(np, key)\n",
    "        @wraps(fn)\n",
    "        def np_fn_wrapper(*args, **kwargs):\n",
    "            fn_args = drop_wrapper(*args)\n",
    "            fn_values = drop_wrapper(*kwargs.values())\n",
    "            kwargs = dict(zip(kwargs.keys(), fn_values))\n",
    "            ret = fn(*fn_args, **kwargs)\n",
    "            if fn in node_functions:\n",
    "                return Node(ret, fn, list(args))\n",
    "            return ret\n",
    "        return np_fn_wrapper\n",
    "\n",
    "    def array(self, *args, **kwargs):\n",
    "        \"\"\"Avoid numpy bug https://github.com/numpy/numpy/issues/9028\"\"\"\n",
    "        return Node(*args, **kwargs)\n",
    "\n",
    "\n",
    "npg = NumpyWrap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need the graph nodes, these require:\n",
    "\n",
    "1. An increasing ID, so we know the order in which the operations have been performed.\n",
    "2. A way of keeping their position in the graph, by keeping a link to the parents.\n",
    "3. Knowledge of what operation resulted in this graph node, so we can find the right JVP.\n",
    "4. The transpose operation, it is needed for the matrix multiplication JVP.\n",
    "5. Operator overload of all operations we may use, so we build the graph nodes as we go.\n",
    "6. Some extras for debugging such as shape or graphviz output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    _max_id = 0\n",
    "\n",
    "    def __new__(cls, val, func=None, parents=None, *args, **kwargs):\n",
    "        if isinstance(val, Node):\n",
    "            return val\n",
    "        obj = super(Node, cls).__new__(cls)\n",
    "        kwargs['dtype'] = np.float64\n",
    "        obj.val = np.array(val, **kwargs)\n",
    "        obj.func = func\n",
    "        obj.func_name = None\n",
    "        if func:\n",
    "            obj.func_name = func.__name__\n",
    "        if not parents:\n",
    "            parents = []\n",
    "        obj.parents = [Node(x) for x in parents]\n",
    "        obj.grads = None\n",
    "        Node._max_id += 1\n",
    "        obj.id = Node._max_id\n",
    "        return obj\n",
    "\n",
    "    def add_grad(self, grad):\n",
    "        if not self.grads:\n",
    "            self.grads = Node(npg.zeros_like(self))\n",
    "        self.grads = self.grads + grad\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Node) and not isinstance(other, np.ndarray):\n",
    "            return False\n",
    "        return npg.allclose(self, other)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.val)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(self.val)\n",
    "\n",
    "    def graph_str(self):\n",
    "        form = ['N {}'.format(self.id),\n",
    "                'Value:',\n",
    "                str(self.val),\n",
    "                'Fn: {}'.format(self.func_name),\n",
    "                'Grads:']\n",
    "        if self.grads:\n",
    "            form.append(str(self.grads))\n",
    "        form.append( 'Parents:')\n",
    "        for p in self.parents:\n",
    "            form.append(str(p.val))\n",
    "        return '\\n'.join(form)\n",
    "\n",
    "    def graphviz(self, graph):\n",
    "        for p in self.parents:\n",
    "            graph.append(f'    {p.id} -> {self.id}')\n",
    "            p.graphviz(graph)\n",
    "        label = self.graph_str().replace('\\n', '\\\\n')\n",
    "        graph.append(f'    {self.id} [label=\"{label}\"]')\n",
    "\n",
    "    def digraph(self):\n",
    "        graph = ['digraph nodes {']\n",
    "        self.graphviz(graph)\n",
    "        graph.append('}')\n",
    "        return '\\n'.join(graph)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        o = Node(other)\n",
    "        return Node(self.val + o.val, op.add, [self, o])\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        o = Node(other)\n",
    "        return Node(o.val + self.val, op.add, [o, self])\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        o = Node(other)\n",
    "        return Node(self.val - o.val, op.sub, [self, o])\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        o = Node(other)\n",
    "        return Node(o.val - self.val, op.sub, [o, self])\n",
    "\n",
    "    def __neg__(self):\n",
    "        return Node(-self.val, op.neg, [self])\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        o = Node(other)\n",
    "        return Node(self.val * o.val, op.mul, [self, o])\n",
    "\n",
    "    def __rmul__(self, other):\n",
    "        o = Node(other)\n",
    "        return Node(o.val * self.val, op.mul, [o, self])\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        o = Node(other)\n",
    "        return Node(self.val / o.val, op.truediv, [self, o])\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        o = Node(other)\n",
    "        return Node(o.val / self.val, op.truediv, [o, self])\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        o = Node(other)\n",
    "        return Node(self.val ** o.val, op.pow, [self, o])\n",
    "\n",
    "    def __rpow__(self, other):\n",
    "        o = Node(other)\n",
    "        return Node(o.val ** self.val, op.pow, [o, self])\n",
    "\n",
    "    def __matmul__(self, other):\n",
    "        o = Node(other)\n",
    "        return Node(self.val @ o.val, op.matmul, [self, o])\n",
    "\n",
    "    def __rmatmul__(self, other):\n",
    "        o = Node(other)\n",
    "        return Node(o.val @ self.val, op.matmul, [o, self])\n",
    "\n",
    "    @property\n",
    "    def T(self):\n",
    "        return Node(self.val.T, np.transpose, [self])\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a graph built we just need something to walk it backwards\n",
    "and apply the JVPs throughout the nodes.\n",
    "\n",
    "We use `inspect` to figure out how many arguments a function passed\n",
    "to `do_grad` has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_nodes(n):\n",
    "    graph = [(n.id, n)]\n",
    "    for p in n.parents:\n",
    "        graph += walk_nodes(p)\n",
    "    return list(dict(graph).items())\n",
    "\n",
    "\n",
    "def do_grad(f, argnums=0, keepgraph=False):\n",
    "    if 'all' == argnums:\n",
    "        spec = inspect.getfullargspec(f)\n",
    "        argnums = list(range(len(spec.args)))\n",
    "    if isinstance(argnums, int):\n",
    "        argnums = [argnums]\n",
    "    @wraps(f)\n",
    "    def grad_func(*args, **kwargs):\n",
    "        wrt = {}\n",
    "        args = list(args)\n",
    "        for i in argnums:\n",
    "            wrt[i] = args[i] = Node(args[i])\n",
    "        ret = f(*args, **kwargs)\n",
    "        # initial gradient (currently a hack, should implement ones_like)\n",
    "        ret.add_grad(Node(npg.ones_like(ret.val, dtype=np.float64)))\n",
    "        nodes = sorted(walk_nodes(ret), key=lambda x: x[0], reverse=True)\n",
    "        for n_id, n in nodes:\n",
    "            if n.func:\n",
    "                vjp = vjps[n.func]\n",
    "                vjp(n, n.parents)\n",
    "        grads = [wrt[x].grads for x in argnums]\n",
    "        if len(grads) == 1:\n",
    "            grads = grads[0]\n",
    "        if keepgraph:\n",
    "            return grads, ret\n",
    "        else:\n",
    "            # zero the grads, in case node-arrays exist in the loss\n",
    "            for _, n in nodes:\n",
    "                n.grads = []\n",
    "        return grads\n",
    "    return grad_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the JVPs themselves.\n",
    "\n",
    "For each operation we may want to differentiate we need a JVP.\n",
    "JVPs are sometimes tricky to build.\n",
    "In other words, JVPs are very short pieces of code but may\n",
    "take one's sleep to get them right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vjps = {}\n",
    "\n",
    "\n",
    "def vjp_add(node, parents):\n",
    "    grad = npg.sum(node.grads)\n",
    "    for p in parents:\n",
    "        p.add_grad(node.grads)\n",
    "vjps[op.add] = vjp_add\n",
    "\n",
    "\n",
    "def vjp_sub(node, parents):\n",
    "    grad = npg.sum(node.grads)\n",
    "    l, r = parents\n",
    "    l.add_grad(node.grads)\n",
    "    r.add_grad(-node.grads)\n",
    "vjps[op.sub] = vjp_sub\n",
    "\n",
    "\n",
    "def vjp_neg(node, parents):\n",
    "    grad = npg.sum(node.grads)\n",
    "    parents[0].add_grad(-node.grads)\n",
    "vjps[op.neg] = vjp_neg\n",
    "\n",
    "\n",
    "def vjp_truediv(node, parents):\n",
    "    grad = npg.sum(node.grads)\n",
    "    l, r = parents\n",
    "    l.add_grad(node.grads / r.val)\n",
    "    r.add_grad(-1 / node.grads**2)\n",
    "vjps[op.truediv] = vjp_truediv\n",
    "\n",
    "\n",
    "def vjp_pow(node, parents):\n",
    "    grad = npg.sum(node.grads)\n",
    "    l, r = parents\n",
    "    l.add_grad(node.grads * r.val * l.val**(r.val - 1))\n",
    "    # log(-x) would give us a complex number,\n",
    "    # instead we support even powers or positive bases only\n",
    "    r.add_grad(node.grads * np.log(npg.abs(l.val)) * l.val**r.val)\n",
    "vjps[op.pow] = vjp_pow\n",
    "\n",
    "\n",
    "def vjp_matmul(node, parents):\n",
    "    grad = npg.sum(node.grads)\n",
    "    l, r = parents\n",
    "    #l.add_grad(grad * r.val.T)\n",
    "    l.add_grad(node.grads @ r.T)\n",
    "    #r.grads.append((grad.T @ l.val).T)\n",
    "    r.add_grad(l.T @ node.grads)\n",
    "vjps[op.matmul] = vjp_matmul\n",
    "\n",
    "\n",
    "def vjp_mean(node, parents):\n",
    "    grad = npg.sum(node.grads)\n",
    "    p = parents[0]\n",
    "    p.add_grad(node.grads / npg.full(p.val.shape, p.val.size / node.val.size))\n",
    "vjps[np.mean] = vjp_mean\n",
    "\n",
    "\n",
    "def vjp_tanh(node, parents):\n",
    "    grad = npg.sum(node.grads)\n",
    "    p = parents[0]\n",
    "    p.add_grad(node.grads * 1 - npg.tanh(npg.tanh(p.val)))\n",
    "vjps[np.tanh] = vjp_tanh\n",
    "\n",
    "\n",
    "def vjp_transpose(node, parents):\n",
    "    grad = npg.sum(node.grads)\n",
    "    p = parents[0]\n",
    "    p.add_grad(node.grads.T)\n",
    "vjps[np.transpose] = vjp_transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it!  The code above is enough to build and train an ANN.\n",
    "Note that we did not use either `pytorch` or `autograd` above.\n",
    "\n",
    "Next we will just build something similar to what we did with `autograd`\n",
    "and execute and train a small ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_exec(l1, b1, l2, b2, l3, b3, X):\n",
    "    W = [l1, l2, l3]\n",
    "    Wb = [b1, b2, b3]\n",
    "    y_hat = X.T\n",
    "    for w, b in zip(W, Wb):\n",
    "        y_hat = npg.tanh(w @ y_hat + b)\n",
    "    return y_hat.T\n",
    "\n",
    "\n",
    "def netMSE(l1, b1, l2, b2, l3, b3, X, y):\n",
    "    y_hat = net_exec(l1, b1, l2, b2, l3, b3, X)\n",
    "    return np.mean(((y_hat - y)**2))\n",
    "\n",
    "\n",
    "netMSE_grad = do_grad(netMSE, argnums='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should run an ANN, and get its gradients.\n",
    "Time to generate an ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 8) (25, 1) (10, 25) (10, 1) (2, 10) (2, 1)\n"
     ]
    }
   ],
   "source": [
    "def layers(neurons):\n",
    "    weights = []\n",
    "    for nl, nr in zip(neurons, neurons[1:]):\n",
    "        weights.append(Node(npg.random.normal(0, 1/npg.sqrt(nr+nl), (nr, nl))))\n",
    "        weights.append(Node(npg.random.normal(0, 1/npg.sqrt(nr+nl), (nr, 1))))\n",
    "    return weights\n",
    "\n",
    "\n",
    "l1, b1, l2, b2, l3, b3 = layers([8, 25, 10, 2])\n",
    "print(l1.shape, b1.shape, l2.shape, b2.shape, l3.shape, b3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's see if our ANN does not blow up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00169501 -0.04085595]\n",
      " [-0.73685352  0.2662274 ]\n",
      " [-0.61084144  0.39672799]\n",
      " ...\n",
      " [ 0.42612149 -0.14190078]\n",
      " [-0.05999345  0.04135883]\n",
      " [-0.72195061  0.28300735]]\n"
     ]
    }
   ],
   "source": [
    "print(net_exec(l1, b1, l2, b2, l3, b3, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, the ANN works, we can build the gradient evaluator.\n",
    "\n",
    "Since we are differentiating against every argument we will need to write all of them.\n",
    "This would be easy to add some syntactic sugar on top but we will keep things simple.\n",
    "Now, the bias terms are broadcasted during the ANN execution.\n",
    "Yet, that also means that their gradients have a broadcasted format.\n",
    "We will need to aggregate them back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 8) (25, 1) (10, 25) (10, 1) (2, 10) (2, 1)\n"
     ]
    }
   ],
   "source": [
    "l1g, b1g, l2g, b2g, l3g, b3g, Xg, yg = netMSE_grad(l1, b1, l2, b2, l3, b3, X, y)\n",
    "b1g = npg.sum(b1g, axis=1)[:, np.newaxis]\n",
    "b2g = npg.sum(b2g, axis=1)[:, np.newaxis]\n",
    "b3g = npg.sum(b3g, axis=1)[:, np.newaxis]\n",
    "print(l1g.shape, b1g.shape, l2g.shape, b2g.shape, l3g.shape, b3g.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still a handful of bugs in the code above,\n",
    "notably the decisions about when to use our graph based `numpy` wrapper\n",
    "and when to use plain `numpy` are not well polished yet.\n",
    "This means that the code below is not very well optimized\n",
    "and may result in quite a high memory usage to keep the graphs.\n",
    "\n",
    "That said, it should be enough to train the ANN at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grochmal/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in log\n",
      "/home/grochmal/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:85: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.412255729886451e-12\n",
      "0.13689817240517962\n",
      "0.06241615721135874\n",
      "0.002149219034025239\n",
      "0.004899996619739444\n",
      "3.880736005494303e-11\n",
      "0.052894994260030574\n",
      "0.0014191994010394834\n",
      "0.021268060862543087\n",
      "0.0048914141911825335\n",
      "1.0929177878328146e-09\n",
      "0.08958589488746166\n",
      "0.009997062117765432\n",
      "0.10239715203196285\n",
      "0.08999982994497342\n",
      "0.028724729671944272\n",
      "4.813469634255193e-05\n",
      "0.13676038838447618\n",
      "0.016888634301367087\n",
      "0.048396510451469234\n"
     ]
    }
   ],
   "source": [
    "netMSE_grad = do_grad(netMSE, argnums='all', keepgraph=True)\n",
    "\n",
    "l1, b1, l2, b2, l3, b3 = layers([8, 25, 10, 2])\n",
    "learning_rate = 0.01\n",
    "batch = 200\n",
    "for i in range(1000):\n",
    "    idx = np.random.randint(0, len(y), batch)\n",
    "    X_sample, y_sample = X[idx], y[idx]\n",
    "    grads, ret = netMSE_grad(l1, b1, l2, b2, l3, b3, X_sample, y_sample)\n",
    "    l1g, b1g, l2g, b2g, l3g, b3g, Xg, yg = drop_wrapper(*grads)\n",
    "    b1g = np.sum(b1g, axis=1)[:, np.newaxis]\n",
    "    b2g = np.sum(b2g, axis=1)[:, np.newaxis]\n",
    "    b3g = np.sum(b3g, axis=1)[:, np.newaxis]\n",
    "    weights = [l1, b1, l2, b2, l3, b3]\n",
    "    grads = [l1g, b1g, l2g, b2g, l3g, b3g]\n",
    "    for j in range(len(weights)):\n",
    "        weights[j] = weights[j] - grads[j]*learning_rate\n",
    "        weights[j].grads = None\n",
    "    if (i+1)%50 == 0:\n",
    "        print(np.mean(ret.val - y_sample)**2)\n",
    "    l1, b1, l2, b2, l3, b3 = [Node(x.val) for x in weights]\n",
    "    del ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick check whether we identified any pulsars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1554\n"
     ]
    }
   ],
   "source": [
    "y_hat = npg.argmax(net_exec(l1, b1, l2, b2, l3, b3, X), axis=1)\n",
    "print(sum(y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally see the performance of our ANN from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8505186089078707\n",
      "0.9023794996949359\n",
      "0.8764490543014033\n"
     ]
    }
   ],
   "source": [
    "y_hat = npg.argmax(net_exec(l1, b1, l2, b2, l3, b3, X), axis=1)\n",
    "y_true = df['label'].values\n",
    "print(sum(y_hat[y_true == 1] == y_true[y_true == 1])/sum(y_true == 1))\n",
    "print(sum(y_hat[y_true == 0] == y_true[y_true == 0])/sum(y_true == 0))\n",
    "print(sum(y_hat == y_true)/len(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the code needed to build an ANN is not very extensive.\n",
    "The mathematics behind it may be complicated at times but the\n",
    "actual code is reasonably short and sweet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
